# e2e-de-azure

This is my first data engineering project and my first non-academic project.

I created an end-to-end pipeline from an on-prem SQL Server Database

I connected Azure Data Factory, Azure Databricks, and Synapse Analytics to this Git repository for audit records and to have a centralized location to run processes from.

The extract/transform/load pipeline accesses and runs the notebooks from "/databricks-notebooks"

The dataset used was the Microsoft lightweight AdventureWorksLT2022 set: https://learn.microsoft.com/en-us/sql/samples/adventureworks-install-configure?view=sql-server-ver16&tabs=ssms

My goal in this project was to learn more about the development stages in a data engineering pipeline, and to gain hands-on practice with the Azure cloud platform and its many tools.

In this project, I used:

- Azure Gen2 Data Lake Storage
- Azure Data Factory
- Azure Databricks
- Microsoft SQL Server
- SQL Server Management Studio (SSMS)
- Azure Synapse Analytics
- Serverless Azure SQL Database
- Azure Entra ID (prev. known as Azure Active Directory)
- Azure Key Vault
- Power BI Desktop

These are the major steps I took in creating this end-to-end project:

- 
